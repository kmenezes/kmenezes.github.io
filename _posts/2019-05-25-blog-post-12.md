---
title: 'Embedded Vision Summit 2019'
date: 2019-05-25
permalink: /posts/2019/06/blog-post-12/
comments: true
author: Keith Menezes
excerpt:
categories:
  - Conference
tags:
  - Reflection
  - Computer Vision
  - Machine Learning
  - Artifical Intelligence
  - Unmanned Aerial Vehicles
---

# May update

This was a big month, because I had a lot going on. 

I'm in the process of designing and building a new first-person view freestyle drone and have reached out to my friends on the Toronto FPV racing group in hopes to attend more meetups this summer. The weather has started to get much better, so I want to get my UAV back up and running. Typically, I was using my UAV with the Pixhawk v1 Flight Controller for mapping and surveying, but this time around I'm looking for a smaller form factor - around 250mm / 5-inch for more casual flight operations. Now there is more clarity about different classes of UAV operations (with Transport Canada's updated Canadian Aviation Regulations, as of June 2019), I've been reviewing my UAV Ground School training with Aerobotika from 2017. Despite the information being from old regulations (2014), I was able to write and passed the Basic RPAS Pilot Operations Certificate with Transport Canada without re-studying. Much of the old regulationâ€™s principles are still valid especially for the Advanced operations certificate, which requires an in-person flight examination from Transport Canada _*approved*_ Flight Schools.

As I was researching flight stacks for FPV racers, I was pretty shocked with how miniaturized and efficient flight controllers have become! I also came across a very interesting project called [NeuroFlight](https://github.com/wil3/neuroflight) that uses Reinforcement Learning to train a Neural Network in replacement of the PID controller. This was cool because I always had a hard time self-tuning and getting it just right and auto-tune in the air always took too long (more than one battery). This allows you to train the model aircraft in a virtual environment (although there are inherent environmental limitations i.e. wind), it does become enticing if the model parameters are realistic. This doesn't mean I will be straying away from my favourite stack [Ardupilot](http://ardupilot.org/). Simply because it supports various typical new emerging vehicle types such as VTOL and compound helicopters as well as its foundation on open software and hardware in addition to companion computer integration all on a real-time deterministic system.

# Embedded Vision Summit 2019

Greg and I were glad to attend Embedded Vision Summit for the first time in Santa Clara, California May 20th-23rd. It is always important to us to stay ahead of the curve on deployed visual intelligence and collaborate with other experts in the field.

I have always been into low-powered devices and deployed machine vision. At one of the lunches, I was sitting next to a man from Infineon and he pulled out three (3) phones each with their technology in it and demonstrated some time-of-flight augmented reality and object scanning. Also, I met some gentlemen from Qualcomm that showed their low-powered face detection module which was palm sized and light-weight. 

Key takeaways for us are the rise of Neural Processing Units (NPUs). These are specialized ASICs that are designed to efficiency and quickly compute fused Multiply and Accumulate operations which are used extensively in convolutions and artificial neural networks. WOLF is looking for ways to enhance our current product offering in the Vision Processing Units (VPUs) to incorporate NPUs as well as support our customers to optimize their Neural Networks for deployment on our hardware to ensure that maximum utilization of every single Operation Per Second, per Watt possible.

_*Embedded Vision Summit is an annual conference held by the Embedded Vision Alliance to stimulate discussion, innovation, and collaboration in the field of computer vision technology and artificial intelligence across multiple different fields medical, robotics, automotive, consumer, industrial, surveillance, and more. 1200+ attendees from over 450 companies and 20 countries will be here for one purpose: To learn and share what it takes to create, build and deploy visual AI and computer vision capabilities.*_

<iframe src="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Fkeith.menezes1%2Fposts%2F10156012449687007&width=500" width="500" height="612" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allow="encrypted-media"></iframe>

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div class="fb-like" data-href="http://keithmenezes.ca/posts/2019/05/blog-post-12/" data-layout="standard" data-action="like" data-size="large" data-show-faces="true" data-share="false"></div>

<div class="fb-send" data-href="http://keithmenezes.ca/posts/2019/05/blog-post-12/"></div>
